{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8007a334-61ad-4c43-83fd-cd5461916789",
   "metadata": {},
   "source": [
    "<a href=\"https://atap.edu.au\"><img src=\"https://www.atap.edu.au/atap-logo.png\" width=\"125\" height=\"50\" align=\"right\"></a>\n",
    "# ATAP: TopSBM\n",
    "\n",
    "*Australian Text Analytics Platform (ATAP) is an open source environment that provides researchers with tools and training for analysing, processing, and exploring text. ATAP: TopSBM is an effort to integrate the TopSBM approach developed by E.G. Altman et al which focuses on analysing and exploring your text.*\n",
    "\n",
    "---\n",
    "\n",
    "**TopSBM** is a topic modelling algorithm. [Topic modelling](https://en.wikipedia.org/wiki/Topic_model) find *topics* within a collection of documents.\n",
    "\n",
    "A *topic* in topic modelling typically refers to a group of related documents from the collection. Note that the step of assigning a word to describe the group is not part of the topic modelling algorithm as opposed to the conventional idea. (However, this is can be achieved later on using a language model e.g. ChatGPT)\n",
    "\n",
    "A *document* refers to the full piece of text and is synonymous to the conventional meaning of the word.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**References**:\n",
    "1. TopSBM: Topic Models based on Stochastic Block Models - https://topsbm.github.io/\n",
    "2. ATAP: Australian Text Analytics Platform - https://www.atap.edu.au/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "018469c6-ec5d-4840-9b26-35c00d733f17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>table {float:left}</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html \n",
    "<style>table {float:left}</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d074772-0fcf-4d7a-9614-cbdfa7797820",
   "metadata": {},
   "source": [
    "## 1. Upload your dataset using the Corpus Loader\n",
    "\n",
    "In the Corpus Loader below, select your dataset and build it as a Corpus.\n",
    "\n",
    "This is the first step in using the TopSBM notebook. Your Corpus should contain a collection of documents, so that *topics* may be inferred by running the TopSBM algorithm.\n",
    "\n",
    "#### Instructions on using the Corpus Loader\n",
    "1. Upload your corpus files using the file browser on the left - ensure the files are in the directory \"corpus_files\". You can simply **drag and drop** your files. Clicking on the folder icon will show you the file explorer pane. Wait until your corpus has uploaded before you return to the notebook.\n",
    "2. Executing the following code cell then makes available the ATAP Corpus Loader.\n",
    "3. Load your files by selecting the files in the selector window and clicking the 'Load as corpus' button. Then select the right datatype label for your file contents. For example, if your file consists of text, the datatype TEXT is appropriate and no changes are necessary. The Corpus Loader also automatically creates and includes filename and filepath as TEXT data.\n",
    "4. Give your corpus a name (optional) and click on the button “Build corpus”. Wait until you receive the message “Corpus … built successfully”. Review your corpus in the Corpus Overview or continue immediately to the next code cell in the notebook.\n",
    "\n",
    "For detailed instructions on how to use the Corpus Loader, including uploading your own datasets, please click <a href=\"Corpus Loader User Guide.pdf\" target=\"_blank\">here</a> to open a PDF.\n",
    "\n",
    "\n",
    "#### Sample datasets\n",
    "+ There are 4 sample datasets: `corpus.csv`, `wiki.csv`, `constitutions.csv`, `arxiv.csv`.\n",
    "\n",
    "    \n",
    "| Dataset      | Description                      | # documents|\n",
    "|:--------------|----------------------------------|-----|\n",
    "| `corpus.csv`    | sourced from [wikipedia](https://wikipedia.org) | 63 |\n",
    "| `wiki.csv`    | sourced from [wikipedia](https://wikipedia.org)       | 120 |\n",
    "| `constitutions.csv`    |   constitutions of various countries       |189 |\n",
    "| `arxiv.csv`    |     sourced from [arxiv.org](https://arxiv.org)    | 2539|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75a1902-3649-4b5d-82b9-5996a0302c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from atap_corpus_loader import CorpusLoader\n",
    "\n",
    "loader = CorpusLoader('datasets')\n",
    "loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da3df49-bce0-40e9-8d8f-e0d053768954",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = loader.get_latest_corpus()\n",
    "f\"Your selected corpus: name={corpus.name} #documents={len(corpus)} meta data: {', '.join(corpus.metas)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da93c63-7123-47c4-bf0f-83666599e63e",
   "metadata": {},
   "source": [
    "## 2. Breaking up your documents into words using a whitespace tokeniser\n",
    "\n",
    "<br>\n",
    "\n",
    "> **In order for TopSBM to infer topics from your documents, you how to break up the *'words'* or *'tokens'* (as the technical term) in your documents.**\n",
    "\n",
    "<br/>\n",
    "The most common tokeniser is to use whitespace as the delimiter.\n",
    "\n",
    "e.g. \"A fox jumped over a lazy fox\" will be broken up into \"A\", \"fox\", \"jumped\", \"over\", \"a\", \"lazy\", \"fox\"\n",
    "\n",
    "\n",
    "<br/>\n",
    "\n",
    "Below cells will use the default tokeniser from [spacy](https://spacy.io/usage/spacy-101#annotations-token) (a popular NLP python library) which is mostly a whitespace tokeniser to break the documents up into words.\n",
    "\n",
    "In order to use spacy, we must first modify the documents in our Corpus as 'spacy' documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc2effd-d97f-4ebf-93ad-b84de036cbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.blank('en')\n",
    "nlp.max_length = 1_500_000  # increase to support long articles up to 1.5m characters\n",
    "corpus.run_spacy(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b71c64-97a5-4a16-bbed-8a34d3667876",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokeniser_fns = {\n",
    "    \"whitespace\": lambda doc: [t.text for t in doc],\n",
    "    \"whitespace_lower_case_only\": lambda doc: [t.text.lower() for t in doc],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01add3d-ecf8-4f57-890f-373720a9c566",
   "metadata": {},
   "source": [
    "### [Optional] Filtering out stop words\n",
    "\n",
    "Some times you might want to remove words from your documents that may not contribute to the overall semantics.\n",
    "\n",
    "Such as, 'the', 'of', 'also', 'am', etc. These words are also known as 'stop words'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9c1c7b-a591-4b1b-bbb5-58a17194c28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.matcher import Matcher\n",
    "\n",
    "matcher = Matcher(nlp.vocab)\n",
    "pattern = [{\"IS_STOP\": False}]  # Match tokens that are not stopwords\n",
    "matcher.add(\"NON_STOPWORDS\", [pattern])\n",
    "\n",
    "filters = {\n",
    "    \"no_stopwords\": matcher,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8172e198-793b-4530-9d47-062f530ed18d",
   "metadata": {},
   "source": [
    "Run the cell below to show the list of stop words used by spacy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90c4690-c117-4fcd-943b-579958f65b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import panel as pn\n",
    "pn.extension()\n",
    "stop_words: str = ', '.join(sorted(set(nlp.Defaults.stop_words), reverse=False))\n",
    "pn.widgets.StaticText(name='SpaCy stop words: ', value=stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aae7bcf-2369-40bd-81aa-dd1ffca47c3d",
   "metadata": {},
   "source": [
    "## 3. TopSBM\n",
    "Now you have everything you need to run TopSBM!\n",
    "\n",
    "As you can see, we're accessing the Corpus's DTM, specifically the 'tokens' DTM as specified before.\n",
    "\n",
    "`model.make_graph(...)` constructs the graph for the model using the information from the DTM.\n",
    "`.model.fit()` will then run the TopSBM algorithm. \n",
    "\n",
    "Once it finishes running, the square bracket indicator on the left of the cell should change from [*] to [\\<number\\>] where \\<number\\> is a placeholder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f111d07-4e0a-4516-8f77-e262bc6ebbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import atap_wrapper as atap\n",
    "\n",
    "list_of_words =  atap.to_list_of_terms(\n",
    "    corpus, \n",
    "    tokeniser_fns['whitespace_lower_case_only'], \n",
    "    filters['no_stopwords'],\n",
    ")\n",
    "titles = corpus['title'].tolist() if 'title' in corpus.metas else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b8924d-72ea-4362-8bc7-4a2e43304197",
   "metadata": {},
   "outputs": [],
   "source": [
    "from topsbm.sbmtm import sbmtm\n",
    "import panel as pn\n",
    "pn.extension()\n",
    "\n",
    "spinner = pn.indicators.LoadingSpinner(value=True, name='Fitting model...', color='success')\n",
    "display(spinner)\n",
    "\n",
    "model = sbmtm()\n",
    "model.make_graph(\n",
    "    list_of_words,\n",
    "    titles,\n",
    ")\n",
    "model.fit()\n",
    "\n",
    "spinner.value=False\n",
    "spinner.name=\"Fitting complete.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11b9e75-9ed4-43f4-b62e-751a042a59e9",
   "metadata": {},
   "source": [
    "## 4. Visualise Outputs in a Radial Cluster\n",
    "\n",
    "Now that the TopSBM has been fitted onto your dataset, you can now visualise the outputs.\n",
    "\n",
    "There are currently 2 visualisations for the model. \n",
    "\n",
    "1. visualise the word groups (i.e. topics) that's been formed for the words.\n",
    "2. visualise the document groups belonging to the same topics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5599d55f-cf36-44e7-8ff5-e52ea72760dc",
   "metadata": {},
   "source": [
    "### 4a. Topics (groups of documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b19533d-bdeb-48d3-bbaf-8478bfdd6350",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_doc = atap.visualise(\n",
    "    model=model, \n",
    "    corpus=corpus, \n",
    "    kind='documents',\n",
    "    hierarchy='radial',\n",
    "    categories=corpus['category'].tolist() if 'category' in corpus.metas else None,\n",
    ")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f4f790-01ea-44d1-aea4-0c765e8eecbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_doc.display(depth=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292d55ca-df68-4358-9c73-00f217fb5dce",
   "metadata": {},
   "source": [
    "### 4b. Topics (groups of words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6a4e90-e76b-46dc-a290-0c33cd4fbeb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_words = atap.visualise(\n",
    "    model=model, \n",
    "    corpus=corpus, \n",
    "    kind='words',\n",
    "    hierarchy='radial',\n",
    "    top_words_for_level=2,\n",
    "    top_num_words=10,\n",
    ")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1307851a-a8fb-4d52-bb10-28bd596cfbcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_words.display(depth=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607676f9-4412-4e20-b30e-88729ed122cb",
   "metadata": {},
   "source": [
    "# 5. More technical: Group membership\n",
    "In the stochastic block model, word (-nodes) and document (-nodes) are clustered into different groups.\n",
    "\n",
    "The group membership can be represented by the conditional probability $P(\\text{group}\\, |\\, \\text{node})$. Since words and documents belong to different groups (the word-document network is bipartite) we can show separately:\n",
    "\n",
    "- P(bd | d), the probability of document $d$ to belong to document group $bd$\n",
    "- P(bw | w), the probability of word $w$ to belong to word group $bw$.ore Technical: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8549150d-1b00-4cd8-b5ec-06e6b225a5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline  \n",
    "import pylab as plt\n",
    "\n",
    "p_td_d,p_tw_w = model.group_membership(l=1)\n",
    "\n",
    "plt.figure(figsize=(15,4))\n",
    "plt.subplot(121)\n",
    "plt.imshow(p_td_d,origin='lower',aspect='auto',interpolation='none')\n",
    "plt.title(r'Document group membership $P(bd | d)$')\n",
    "plt.xlabel('Document d (index)')\n",
    "plt.ylabel('Document group, bd')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.imshow(p_tw_w,origin='lower',aspect='auto',interpolation='none')\n",
    "plt.title(r'Word group membership $P(bw | w)$')\n",
    "plt.xlabel('Word w (index)')\n",
    "plt.ylabel('Word group, bw')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a1f453-a385-4c6a-a468-be6fe783ef91",
   "metadata": {},
   "source": [
    "## Relative Topic Distribution\n",
    "Compare the frequency $f^i_d$ of words from topic $i$ in document $d$ with the expected value across all documents:\n",
    "\n",
    "$$ \\tau_d^i = (f^i_d -\\langle f^i \\rangle ) / \\langle f^i \\rangle $$\n",
    "\n",
    "as in Eq. (10) of Hyland et al."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0cf99e-3831-4e40-897a-4e27e2a0c645",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.print_overview()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e463c255-e360-460c-9ba5-8a90e5a36c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.topics(l=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4aef878-1ae9-4d78-b25e-1e9f2d3336a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Document title [relative contribution of each topic]\\n\")\n",
    "tau_d=model.topicdist_relative(l=2)\n",
    "\n",
    "for i in range(len(model.documents)):\n",
    "    print(model.documents[i],tau_d[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a542ccce-d2fb-43bd-9fb6-a964e1092f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.docs_of_topic(l=2, n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b51196d-fbfc-4826-af54-14f637ec66b7",
   "metadata": {},
   "source": [
    "# 6. Export TopSBM's results for your Corpus\n",
    "\n",
    "> First, we'll add the results from TopSBM as meta data into our Corpus.\n",
    "> \n",
    "> This will retain the cluster that each document belongs for each of levels inferred by TopSBM.\n",
    "\n",
    "Then, export the Corpus using Corpus Loader from before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a566bf18-b433-4e2c-9758-77ab298f308a",
   "metadata": {},
   "outputs": [],
   "source": [
    "atap.add_results(model, corpus)\n",
    "print(f\"Metadata in your Corpus after added results:\\n{', '.join(corpus.metas)}\\n\")\n",
    "\n",
    "print(\"\"\"\n",
    "Below displays Corpus-level metadata called 'attributes' which retains the information on where the added metadata is sourced from.\n",
    "\"\"\".strip())\n",
    "pn.pane.JSON(corpus.attributes, hover_preview=True, depth=-1, theme='light')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8c3905-fff5-4062-b21c-bde8a614f4b6",
   "metadata": {},
   "source": [
    "**Export** the corpus using our corpus loader from before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1050d8b9-ca9f-43a1-8d17-83a4fdf30344",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Export corpus you fitted the model on: i.e. name = '{corpus.name}'\")\n",
    "loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0457f862-82c0-412f-b459-85f9bcde2b5d",
   "metadata": {},
   "source": [
    "<a href=\"https://atap.edu.au\"><img src=\"https://www.atap.edu.au/atap-logo.png\" width=\"125\" height=\"50\" align=\"right\"></a>\n",
    "## Bring your Corpus with TopSBM results to other ATAP Tools!\n",
    "\n",
    "You will find the familiar ATAP Corpus Loader interface and continue your analysis.\n",
    "\n",
    "Link to a collection of ATAP tools - https://www.atap.edu.au/tools/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441978c4-7603-4a0c-9810-24590f49e962",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
